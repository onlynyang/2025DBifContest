{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.25.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.7.4)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색어를 포함하는 기사 크롤링\n",
    "\n",
    "> 검색어\n",
    "\n",
    " ‘TI((\"Trump\") AND (\"climate\" OR \"environmental regulation*\" OR \"EPA\" OR \"clean energy\" OR \"fossil fuel*\" OR \"carbon tax*\" OR \"green policy*\" OR \"Clean Power\" OR \"Paris Agreement\" OR \"pipeline approval*\" OR \"oil drilling*\" OR \"coal industry*\" OR \"fracking\" OR \"auto emission standard*\" OR \"renewable energy\" OR \"electric vehicle*\" OR \"solar energy policy*\" OR \"offshore drilling*\" OR \"deforestation\" OR \"endangered species protection*\") AND (\"policy\" OR \"order\" OR \"speech\" OR \"statement\" OR \"bill\" OR \"signing\" OR \"announcement\" OR \"withdrawal\" OR \"legislation\"))’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 크롤링 중: 1페이지\n",
      "📄 크롤링 중: 2페이지\n",
      "📄 크롤링 중: 3페이지\n",
      "📄 크롤링 중: 4페이지\n",
      "📄 크롤링 중: 5페이지\n",
      "📄 크롤링 중: 6페이지\n",
      "📄 크롤링 중: 7페이지\n",
      "📄 크롤링 중: 8페이지\n",
      "📄 크롤링 중: 9페이지\n",
      "📄 크롤링 중: 10페이지\n",
      "📄 크롤링 중: 11페이지\n",
      "📄 크롤링 중: 12페이지\n",
      "📄 크롤링 중: 13페이지\n",
      "📄 크롤링 중: 14페이지\n",
      "📄 크롤링 중: 15페이지\n",
      "📄 크롤링 중: 16페이지\n",
      "📄 크롤링 중: 17페이지\n",
      "📄 크롤링 중: 18페이지\n",
      "📄 크롤링 중: 19페이지\n",
      "📄 크롤링 중: 20페이지\n",
      "📄 크롤링 중: 21페이지\n",
      "📄 크롤링 중: 22페이지\n",
      "📄 크롤링 중: 23페이지\n",
      "📄 크롤링 중: 24페이지\n",
      "🚫 다음 페이지 없음. 크롤링 종료.\n",
      "✅ 크롤링 완료: ProQuest_Articles.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# ChromeDriver 경로 설정\n",
    "chrome_driver_path = \"C:/Users/chica/Downloads/chromedriver-win64(131.0.6778.85)/chromedriver-win64/chromedriver.exe\"\n",
    "\n",
    "# WebDriver 옵션 설정\n",
    "options = Options()\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\")\n",
    "options.add_argument(\"--start-maximized\")  # 창 최대화\n",
    "\n",
    "# WebDriver 초기화\n",
    "service = Service(chrome_driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# ProQuest 접속\n",
    "url = \"https://www.proquest.com\"\n",
    "driver.get(url)\n",
    "time.sleep(3)  # 페이지 로딩 대기\n",
    "\n",
    "# 검색어 입력\n",
    "search_term = 'TI((\"Trump\") AND (\"climate\" OR \"environmental regulation*\" OR \"EPA\" OR \"clean energy\" OR \"fossil fuel*\" OR \"carbon tax*\" OR \"green policy*\" OR \"Clean Power\" OR \"Paris Agreement\" OR \"pipeline approval*\" OR \"oil drilling*\" OR \"coal industry*\" OR \"fracking\" OR \"auto emission standard*\" OR \"renewable energy\" OR \"electric vehicle*\" OR \"solar energy policy*\" OR \"offshore drilling*\" OR \"deforestation\" OR \"endangered species protection*\") AND (\"policy\" OR \"order\" OR \"speech\" OR \"statement\" OR \"bill\" OR \"signing\" OR \"announcement\" OR \"withdrawal\" OR \"legislation\"))'  \n",
    "search_box = driver.find_element(By.ID, \"searchTerm\")  # 검색 입력 필드 찾기\n",
    "search_box.send_keys(search_term)\n",
    "\n",
    "# 검색 버튼 클릭\n",
    "search_button = driver.find_element(By.XPATH, \"//a[@id='expandedSearch']\")\n",
    "search_button.click()\n",
    "time.sleep(5)  # 검색 결과 로딩 대기\n",
    "\n",
    "# URL 끝에 '#0' 추가\n",
    "current_url = driver.current_url  # 현재 URL 가져오기\n",
    "new_url = current_url + \"#0\"\n",
    "driver.get(new_url)  # 새 URL 로드\n",
    "time.sleep(5)  # 페이지 로딩 대기\n",
    "\n",
    "# 3번: '신문' 필터 적용 (기존 filter_3 클릭 방식)\n",
    "try:\n",
    "    newspaper_filter = driver.find_element(By.ID, \"filter_3\")  # '신문' 필터 버튼 찾기\n",
    "    newspaper_filter.click()\n",
    "    time.sleep(5)  # 필터 적용 후 대기\n",
    "except Exception as e:\n",
    "    print(\"신문 필터 클릭 오류:\", e)\n",
    "\n",
    "\n",
    "# CSV 파일 저장\n",
    "csv_filename = \"ProQuest_Articles.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Title\", \"Source\", \"Date\"])\n",
    "\n",
    "    # 4~6번: 24페이지까지 크롤링 반복\n",
    "    for page in range(1, 25):\n",
    "        print(f\"📄 크롤링 중: {page}페이지\")\n",
    "\n",
    "        # 논문 리스트 가져오기\n",
    "        articles = driver.find_elements(By.XPATH, \"//ul[@class='resultItems']/li[@class='resultItem ltr']\")\n",
    "\n",
    "        for article in articles:\n",
    "            try:\n",
    "                # 제목 가져오기\n",
    "                title = article.find_element(By.XPATH, \".//h3[contains(@id, 'result-header')]//a\").text.strip()\n",
    "\n",
    "                # 출처 가져오기\n",
    "                source = article.find_element(By.XPATH, \".//span[@class='newspaperArticle']//strong\").text.strip()\n",
    "\n",
    "                # 날짜 가져오기\n",
    "                date_info = article.find_element(By.XPATH, \".//span[@class='newspaperArticle']\").text.strip().split(\"\\n\")[-1]\n",
    "\n",
    "                # CSV 저장\n",
    "                writer.writerow([title, source, date_info])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 데이터 크롤링 오류: {e}\")\n",
    "\n",
    "        # '다음' 버튼 클릭하여 다음 페이지 이동\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, \"//a[@title='다음 페이지']\")\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # 페이지 로딩 대기\n",
    "        except Exception:\n",
    "            print(\"🚫 다음 페이지 없음. 크롤링 종료.\")\n",
    "            break  # 더 이상 다음 페이지가 없으면 종료\n",
    "\n",
    "print(f\"✅ 크롤링 완료: {csv_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### source 열 정제\n",
    "- 날짜 이전 텍스트 삭제\n",
    "- 날짜 이후 텍스트 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터 정제 완료: ProQuest_Articles_Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# CSV 파일 로드\n",
    "input_csv = \"ProQuest_Articles.csv\"\n",
    "output_csv = \"ProQuest_Articles_Cleaned.csv\"\n",
    "\n",
    "with open(input_csv, \"r\", newline=\"\", encoding=\"utf-8-sig\") as infile, open(output_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # 헤더 복사\n",
    "    header = next(reader)\n",
    "    writer.writerow(header)  # [\"Title\", \"Source\", \"Date\"]\n",
    "\n",
    "    # 데이터 정제 및 저장\n",
    "    for row in reader:\n",
    "        title, source, date_info = row\n",
    "\n",
    "        # \"..\" 이전의 모든 문자 제거하여 날짜만 남김\n",
    "        cleaned_date = re.sub(r\".*?\\.\\.\", \"\", date_info).strip()\n",
    "\n",
    "        # 새로운 CSV 파일에 저장\n",
    "        writer.writerow([title, source, cleaned_date])\n",
    "\n",
    "print(f\"✅ 데이터 정제 완료: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터 정제 완료: ProQuest_Articles_Cleaned2.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# CSV 파일 로드\n",
    "input_csv = \"ProQuest_Articles_Cleaned.csv\"\n",
    "output_csv = \"ProQuest_Articles_Cleaned2.csv\"\n",
    "\n",
    "with open(input_csv, \"r\", newline=\"\", encoding=\"utf-8-sig\") as infile, open(output_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # 헤더 복사\n",
    "    header = next(reader)\n",
    "    writer.writerow(header)  # [\"Title\", \"Source\", \"Date\"]\n",
    "\n",
    "    # 데이터 정제 및 저장\n",
    "    for row in reader:\n",
    "        title, source, date_info = row\n",
    "\n",
    "        # \";\" 이전의 모든 문자열 제거 (..은 유지)\n",
    "        cleaned_date = re.sub(r\"^.*?;\", \"\", date_info).strip()\n",
    "\n",
    "        # 새로운 CSV 파일에 저장\n",
    "        writer.writerow([title, source, cleaned_date])\n",
    "\n",
    "print(f\"✅ 데이터 정제 완료: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 번역 시도\n",
    "- 번역이 되었으나 약 100행 단위로만 24시간마다 가능함.\n",
    "- trans 라이브러리가 더 자연스럽게 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from googletrans import Translator\n",
    "\n",
    "# CSV 파일 로드\n",
    "input_csv = \"ProQuest_Articles_Cleaned.csv\"\n",
    "output_csv = \"ProQuest_Articles_Translated.csv\"\n",
    "\n",
    "# 번역기 초기화\n",
    "translator = Translator()\n",
    "\n",
    "with open(input_csv, \"r\", newline=\"\", encoding=\"utf-8-sig\") as infile, open(output_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # 헤더 복사\n",
    "    header = next(reader)\n",
    "    writer.writerow([\"제목\", \"출처\", \"날짜\"])  # 한국어 헤더로 변경\n",
    "\n",
    "    # 데이터 번역 및 저장\n",
    "    for row in reader:\n",
    "        title, source, date_info = row\n",
    "\n",
    "        # 제목과 출처 번역 (날짜는 번역 X)\n",
    "        translated_title = translator.translate(title, src=\"en\", dest=\"ko\").text\n",
    "        translated_source = translator.translate(source, src=\"en\", dest=\"ko\").text\n",
    "\n",
    "        # 새로운 CSV 파일에 저장\n",
    "        writer.writerow([translated_title, translated_source, date_info])\n",
    "\n",
    "print(f\"✅ 번역 완료: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date열 필터링\n",
    "2025~2022을 포함한 행은 삭제하도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚫 삭제된 행 (제외 연도 포함): ['Liberals, Trump climate policy opposites; Ottawa brags about carbon tax while president-elect set to axe green agenda', 'Star - Phoenix', '15 Nov 2024: A.5.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Liberals, Trump climate policy opposites; Ottawa brags about carbon tax while president-elect set to axe green agenda', 'Leader Post', '15 Nov 2024: A.5.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Liberals, Trump diverge on climate change policy; Ottawa brags about carbon tax while president-elect set to axe green agenda', 'Edmonton Journal', '13 Nov 2024: A.2.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Liberals, Trump diverge on climate policy; Ottawa brags about carbon tax while president-elect set to axe green agenda', 'Calgary Herald', '13 Nov 2024: A.2.']\n",
      "🚫 삭제된 행 (제외 연도 포함): [\"Officials reviewing Trump's electric vehicle order\", 'Battle Creek Enquirer', '26 Jan 2025: A.1.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Mr. Trump is bad for green policy. Ms. Harris could be better.', 'The Washington Post', '18 Aug 2024: A.23.']\n",
      "🚫 삭제된 행 (제외 연도 포함): [\"Biden order expands Trump's offshore drilling ban from 2020\", 'The Louisiana Weekly', '13 Jan 2025: 13,17.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Trump order freezes funding for Illinois EV charging network: Move raises questions about other clean energy projects', 'Chicago Tribune', '27 Jan 2025: 1.']\n",
      "🚫 삭제된 행 (제외 연도 포함): [\"Trump's second withdrawal from Paris Agreement to cast a shadow over global climate action and new mitigation pledges [US]\", 'The Times of India', 'New Delhi. 22 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Harris, Trump sharply split on climate policy: Where both candidates stand on key issues', 'The Daily World', '25 Aug 2024: A.6.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Global markets are likely to withstand a Trump-led US withdrawal from the Paris Agreement', 'EveningReport.nz', 'Auckland. 04 Dec 2024.']\n",
      "🚫 삭제된 행 (제외 연도 포함): [\"Trump's climate picks worry green advocates: Local leaders highlight resilience, bipartisan efforts, and economic benefits amid shifting federal policy\", 'Rochester Democrat and Chronicle', '16 Dec 2024: A.1.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['President Donald Trump’s announcement of US pullout from 2015 Paris Agreement sparks uncertainty', 'The Telegraph (India)', 'Calcutta. 22 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Waaree Energies sinks 7% amid renewable energy stocks rout on Trump policy fears [Stock in news]', 'The Economic Times', 'New Delhi. 22 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Waaree Energies shares plunge 9% as renewable energy selloff deepens on Trump policy fears [Stock in news]', 'The Economic Times', 'New Delhi. 27 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Express View on Trump’s withdrawal from Paris Accord: Climate change challenge just got more challenging', 'Indian Express', 'Mumbai. 22 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['What Trump can do to reverse US climate policy − and what he probably can’t change', 'The Conversation : Environment + Energy', 'Boston. 07 Nov 2024.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Two US govs dare Trump, vow to continue action on climate change despite Paris withdrawal', 'Vanguard', 'Lagos. 21 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Climate change experts gird for policy fight with Trump', 'USA TODAY', '20 Nov 2024: A.1.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Climate change experts gird for policy fight with Trump', 'USA TODAY', '20 Nov 2024: A.1.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Trump should listen to Exxon on climate policy reversals', 'Bangor Daily News', '14 Nov 2024.']\n",
      "🚫 삭제된 행 (제외 연도 포함): [\"Climate Change Bill: Zim's trump card\", 'The Herald', 'Harare. 28 June 2024.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Trump executive orders target climate, immigration policy, federal employees', 'Yerepouni Daily News', 'Beirut. 21 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['VIDEO: Trump signs order to pull US out of Paris climate agreement', 'The New Vision', 'Kampala. 21 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['As Teenagers, They Protested Trump’s Climate Policy. Now What?', 'New York Times', '11 Dec 2024.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['President Donald Trump signs executive order withdrawing US from Paris climate accord', 'The Hindustan Times', 'New Delhi. 21 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['World: Donald Trump signs executive order to withdraw US from Paris Climate Accord', 'Asia News Monitor', 'Bangkok. 24 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['United States: Trump signs executive order withdrawing US from Paris Climate Agreement again', 'Asia News Monitor', 'Bangkok. 23 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['In sweeping orders, Trump aims to remake federal policy on border, gender, climate change', 'USA Today (Online)', 'Arlington. 20 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Get rid of all cows’: Trump campaign spreads myths about Harris’s climate policy', 'The New Vision', 'Kampala. 18 Aug 2024.']\n",
      "🚫 삭제된 행 (제외 연도 포함): [\"Trump's re-election sparks climate policy shift: US at a crossroads amid global action\", 'The Pioneer', 'New Delhi. 23 Nov 2024.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['CEO of World’s Largest Sovereign Wealth Fund Disagrees with Trump’s Climate Policy', 'The New York Observer', '24 Jan 2025.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['What Trump can do to reverse US climate policy − and what he probably can’t change', 'The Conversation : Economy + Business', 'Boston. 07 Nov 2024.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['What Trump can do to reverse US climate policy − and what he probably can’t change', 'The Conversation U.S', 'Boston. 07 Nov 2024.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Trade Policy and Clean Energy Investments Will Be Key Issues in Likely Trump-Biden Rematch: [Business/Financial Desk]', 'New York Times', '29 Jan 2024: B.2.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Critics say the Trump-era wetland rules not for Fla.: Groups inform EPA state still using policy rejected in court 2 years ago', 'The News Press', '21 Feb 2023: A.3.']\n",
      "🚫 삭제된 행 (제외 연도 포함): ['Conservative Arizona lawmaker used campaign cash for Jan. 6 travel, complaint alleges Arizona Republic A Democratic voter and liberal group accuse conservative state Sen. Anthony Kern of misusing campaign cash in his travel to Washington on', 'Yellow Sheet Report', 'Phoenix. 01 Nov 2023.']\n",
      "🚫 삭제된 행 (제외 연도 포함): [\"Solar chief attacks Biden's climate policy: Energy Solv boss claims mixed messages are worse than Trump amid tariff probe\", 'Financial Times', 'London (UK). 04 Apr 2022: 9.']\n",
      "🚫 삭제된 행 (제외 연도 포함): [\"Trump blasts the Democratic-led climate and tax bill, says 'old broken crow' Mitch McConnell was 'taken for a ride' by Joe Manchin\", 'Business Insider', 'New York. 06 Aug 2022.']\n",
      "✅ 숫자 필터링 + 연도 제외 완료: ProQuest_Articles_Cleaned2_Filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# CSV 파일 로드\n",
    "input_csv = \"ProQuest_Articles_Cleaned2.csv\"  # 번역된 CSV 파일\n",
    "output_csv = \"ProQuest_Articles_Cleaned2_Filtered.csv\"  # 숫자가 포함되고 2025~2022 연도가 없는 행만 저장할 파일\n",
    "\n",
    "with open(input_csv, \"r\", newline=\"\", encoding=\"utf-8-sig\") as infile, open(output_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # 헤더 복사\n",
    "    header = next(reader)\n",
    "    writer.writerow(header)  # [\"제목\", \"출처\", \"날짜\"]\n",
    "\n",
    "    # 데이터 필터링 및 저장\n",
    "    for row in reader:\n",
    "        title, source, date_info = row\n",
    "\n",
    "        # 날짜 열(date_info)에 숫자가 하나라도 포함되어 있어야 함\n",
    "        if not re.search(r\"\\d\", date_info):  # 숫자가 없는 행 삭제\n",
    "            print(f\"🚫 삭제된 행 (숫자 없음): {row}\")\n",
    "            continue\n",
    "        \n",
    "        # 2025, 2024, 2023, 2022 포함된 행 삭제\n",
    "\n",
    "        if re.search(r\"2025|2024|2023|2022\", date_info):\n",
    "            print(f\"🚫 삭제된 행 (제외 연도 포함): {row}\")\n",
    "            continue\n",
    "\n",
    "        # 유효한 행만 저장\n",
    "        writer.writerow([title, source, date_info])\n",
    "\n",
    "print(f\"✅ 숫자 필터링 + 연도 제외 완료: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중복 행 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 완료! 저장된 파일: ProQuest_Articles_Unique.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 불러오기\n",
    "file_path = \"ProQuest_Articles_Cleaned2_Filtered.csv\"  # 로컬에 있는 파일 경로\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Title 열을 기준으로 중복된 행 제거 (첫 번째만 유지)\n",
    "df = df.drop_duplicates(subset=[\"Title\"], keep=\"first\")\n",
    "\n",
    "# 중복 제거된 데이터를 새로운 CSV 파일로 저장\n",
    "output_path = \"ProQuest_Articles_Unique.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"중복 제거 완료! 저장된 파일: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파파고 api로 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 번역 완료: ProQuest_Articles_Translated_2.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# ✅ 네이버 클라우드 플랫폼 API 인증 정보 (본인 키로 변경)\n",
    "api_key_id = \"tnr6a2vdi5\"\n",
    "api_key_secret = \"hKui4WvCaeaHkR3Zjje8Xio9j2zk6DZTsGRjMw2t\"\n",
    "\n",
    "# ✅ 올바른 API 요청 URL\n",
    "url = \"https://naveropenapi.apigw.ntruss.com/nmt/v1/translation\"\n",
    "\n",
    "def translate_papago(text):\n",
    "    \"\"\"네이버 Papago NMT API를 사용하여 영어 → 한국어 번역\"\"\"\n",
    "    if not text.strip():  # 빈 문자열이면 그대로 반환\n",
    "        return text\n",
    "\n",
    "    headers = {\n",
    "        \"x-ncp-apigw-api-key-id\": api_key_id,  # ✅ 공식 문서에 맞게 수정\n",
    "        \"x-ncp-apigw-api-key\": api_key_secret,  # ✅ 공식 문서에 맞게 수정\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"source\": \"en\",  # 원문 언어 (영어)\n",
    "        \"target\": \"ko\",  # 번역 언어 (한국어)\n",
    "        \"text\": text,\n",
    "        'honorific': \"false\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=data)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get(\"message\", {}).get(\"result\", {}).get(\"translatedText\", text)\n",
    "        elif response.status_code == 429:\n",
    "            print(\"⚠️ 요청이 너무 많습니다. 1초 대기 후 재시도합니다.\")\n",
    "            time.sleep(1)  # 요청 속도 제한 방지\n",
    "            return translate_papago(text)\n",
    "        else:\n",
    "            print(f\"⚠️ 번역 오류: {response.status_code} - {response.text}\")\n",
    "            return text  # 에러 발생 시 원문 유지\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ API 요청 중 오류 발생: {str(e)}\")\n",
    "        return text  # 네트워크 오류 발생 시 원문 유지\n",
    "\n",
    "# ✅ CSV 파일 로드\n",
    "input_csv = \"ProQuest_Articles_Unique.csv\"  # 원본 파일\n",
    "output_csv = \"ProQuest_Articles_Translated_2.csv\"  # 번역된 파일\n",
    "\n",
    "with open(input_csv, \"r\", newline=\"\", encoding=\"utf-8-sig\") as infile, open(output_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # ✅ 헤더 읽기 및 번역된 Title 열 추가\n",
    "    header = next(reader)\n",
    "    writer.writerow(header + [\"Title_Translated\"])  # 기존 헤더 + 번역된 Title 열\n",
    "\n",
    "    # ✅ 데이터 번역 및 저장\n",
    "    for row in reader:\n",
    "        if len(row) < 1:  # 데이터가 비어 있으면 스킵\n",
    "            continue\n",
    "\n",
    "        title = row[0]  # 첫 번째 열 (Title)\n",
    "        translated_title = translate_papago(title)  # ✅ Papago API 호출하여 번역\n",
    "\n",
    "        writer.writerow(row + [translated_title])  # ✅ 기존 데이터 유지 + 번역된 Title 추가\n",
    "\n",
    "        time.sleep(0.5)  # ✅ API 요청 속도 제한 방지 (0.5초 대기)\n",
    "\n",
    "print(f\"✅ 번역 완료: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이벤트 스터디 사용을 위한 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TrumpFiltered.xlsx`: 트럼프 1기동안 트럼프의 반환경적 행보만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chica\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chica\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 날짜 YYYY-MM-DD 형식으로 변환\n",
    "- Nan 값은 직접 확인 후 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Title        Date  \\\n",
      "43      Bill to trump local bans on fracking advances  2015-12-03   \n",
      "44     House OKs bill to trump local bans on fracking  2016-01-28   \n",
      "1   Trump Stresses Fossil Fuel Agenda In Energy Po...  2016-09-23   \n",
      "24  Trump to slash and burn Obama climate policy: ...  2016-11-14   \n",
      "14  BILL NELSON SAYS DONALD TRUMP INTENDS TO EXPAN...  2016-11-22   \n",
      "\n",
      "                       Title_Translated  \\\n",
      "43             프래킹 어드밴스에 대한 지역 금지 법안 통과   \n",
      "44              하원, 프래킹에 대한 지역 금지 법안 통과   \n",
      "1          트럼프, 에너지 정책 연설에서 화석 연료 의제 강조   \n",
      "24      트럼프, 오바마 기후 정책 삭감 및 소각: 미국에서 보기   \n",
      "14  빌 넬슨, 도널드 트럼프가 석유 시추를 확대할 계획이라고 말하다   \n",
      "\n",
      "                                       GPT_Translated  \n",
      "43  그런데 이 법안이 통과되면, 개별 지역이 프래킹을 금지하는 권한이 없어지고, 프래킹...  \n",
      "44                                                NaN  \n",
      "1                                                 NaN  \n",
      "24  \"트럼프, 오바마의 기후 정책을 대대적으로 철폐할 예정: 미국의 시각에서\"라는 의미...  \n",
      "14                                                NaN  \n",
      "✅ 정리 완료! 새로운 파일 저장됨: Cleaned_Trump_Events.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# 📌 엑셀 파일 불러오기\n",
    "file_path = \"C:/Users/chica/OneDrive/바탕 화면/DB금융 공모전/TrumpFiltered.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 📌 날짜(Date) 추출 함수\n",
    "def extract_date(text):\n",
    "    if pd.isna(text):  # NaN 값은 그대로 유지\n",
    "        return None  # NaT 처리를 위해 None 반환\n",
    "    match = re.search(r\"(\\d{1,2} [A-Za-z]+ \\d{4})\", str(text))\n",
    "    if match:\n",
    "        date_str = match.group(1)\n",
    "        for fmt in (\"%d %b %Y\", \"%d %B %Y\"):\n",
    "            try:\n",
    "                return datetime.strptime(date_str, fmt).date()  # 📌 시간 제거하고 날짜만 반환\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return None  # 변환 실패 시 NaT로 설정\n",
    "\n",
    "# 📌 Date 열 변환 (NaN 값은 유지)\n",
    "df[\"Date\"] = df[\"Date\"].apply(extract_date)\n",
    "\n",
    "# 📌 날짜 정렬 (NaN 값은 그대로 유지)\n",
    "df = df.sort_values(by=\"Date\", na_position=\"last\")\n",
    "\n",
    "# 📌 정리된 데이터 확인\n",
    "print(df.head())\n",
    "\n",
    "# 📌 새로운 파일로 저장\n",
    "output_path = \"Cleaned_Trump_Events.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ 정리 완료! 새로운 파일 저장됨: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 이벤트 날짜 리스트 (중복 제거됨): ['2017-01-25', '2017-02-14', '2017-02-27', '2017-03-19', '2017-03-28', '2017-04-28', '2017-06-01', '2017-10-13', '2017-12-14', '2017-12-19', '2018-06-19', '2018-08-21', '2018-11-26', '2019-04-12', '2019-06-20', '2019-11-04', '2020-06-09', '2020-11-01']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📌 엑셀 파일 불러오기\n",
    "file_path = \"../데이터/Choice_Trump_Events.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 📌 날짜(Date) 열에서 중복 제거한 리스트 생성\n",
    "event_dates = list(set(df[\"Date\"].dropna().astype(str)))  # 중복 제거 후 리스트 변환\n",
    "\n",
    "# 📌 정렬 (중복 제거 후 날짜 정렬)\n",
    "event_dates.sort()\n",
    "\n",
    "# 📌 결과 확인\n",
    "print(\"✅ 이벤트 날짜 리스트 (중복 제거됨):\", event_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
